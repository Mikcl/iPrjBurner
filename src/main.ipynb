{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bite9089b7c8fc14c7e8e610a32fb5dcf2b",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import PIL.Image, PIL.ImageDraw\n",
    "import base64\n",
    "import zipfile\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Image, HTML, clear_output\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CellT\n",
    "from model import CellCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np2pil(a):\n",
    "  if a.dtype in [np.float32, np.float64]:\n",
    "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
    "  return PIL.Image.fromarray(a)\n",
    "\n",
    "def imwrite(f, a, fmt=None):\n",
    "  a = np.asarray(a)\n",
    "  if isinstance(f, str):\n",
    "    fmt = f.rsplit('.', 1)[-1].lower()\n",
    "    if fmt == 'jpg':\n",
    "      fmt = 'jpeg'\n",
    "    f = open(f, 'wb')\n",
    "  np2pil(a).save(f, fmt, quality=95)\n",
    "\n",
    "def imencode(a, fmt='jpeg'):\n",
    "  a = np.asarray(a)\n",
    "  if len(a.shape) == 3 and a.shape[-1] == 4:\n",
    "    fmt = 'png'\n",
    "  f = io.BytesIO()\n",
    "  imwrite(f, a, fmt)\n",
    "  return f.getvalue()\n",
    "\n",
    "def im2url(a, fmt='jpeg'):\n",
    "  encoded = imencode(a, fmt)\n",
    "  base64_byte_string = base64.b64encode(encoded).decode('ascii')\n",
    "  return 'data:image/' + fmt.upper() + ';base64,' + base64_byte_string\n",
    "\n",
    "def imshow(a, fmt='jpeg'):\n",
    "  display(Image(data=imencode(a, fmt)))\n",
    "\n",
    "def tile2d(a, w=None):\n",
    "  a = np.asarray(a)\n",
    "  if w is None:\n",
    "    w = int(np.ceil(np.sqrt(len(a))))\n",
    "  th, tw = a.shape[1:3]\n",
    "  pad = (w-len(a))%w\n",
    "  a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n",
    "  h = len(a)//w\n",
    "  a = a.reshape([h, w]+list(a.shape[1:]))\n",
    "  a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n",
    "  return a\n",
    "\n",
    "def zoom(img, scale=4):\n",
    "  img = np.repeat(img, scale, 0)\n",
    "  img = np.repeat(img, scale, 1)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoWriter:\n",
    "  def __init__(self, filename, fps=30.0, **kw):\n",
    "    self.writer = None\n",
    "    self.params = dict(filename=filename, fps=fps, **kw)\n",
    "\n",
    "  def add(self, img):\n",
    "    img = np.asarray(img)\n",
    "    if self.writer is None:\n",
    "      h, w = img.shape[:2]\n",
    "      self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n",
    "    if img.dtype in [np.float32, np.float64]:\n",
    "      img = np.uint8(img.clip(0, 1)*255)\n",
    "    if len(img.shape) == 2:\n",
    "      img = np.repeat(img[..., None], 3, -1)\n",
    "    self.writer.write_frame(img)\n",
    "\n",
    "  def close(self):\n",
    "    if self.writer:\n",
    "      self.writer.close()\n",
    "\n",
    "  def __enter__(self):\n",
    "    return self\n",
    "\n",
    "  def __exit__(self, *kw):\n",
    "    self.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Cellular Automata Parameters\n",
    "CHANNEL_N = 16        # Number of CA state channels\n",
    "TARGET_PADDING = 16   # Number of pixels used to pad the target image border\n",
    "TARGET_SIZE = 40\n",
    "BATCH_SIZE = 8\n",
    "POOL_SIZE = 1024\n",
    "CELL_FIRE_RATE = 0.5\n",
    "\n",
    "TARGET_EMOJI = \"ðŸ¦Ž\" #@param {type:\"string\"}\n",
    "\n",
    "EXPERIMENT_TYPE = \"Growing\" #@param [\"Growing\", \"Persistent\", \"Regenerating\"]\n",
    "EXPERIMENT_MAP = {\"Growing\":0, \"Persistent\":1, \"Regenerating\":2}\n",
    "EXPERIMENT_N = EXPERIMENT_MAP[EXPERIMENT_TYPE]\n",
    "\n",
    "USE_PATTERN_POOL = [0, 1, 1][EXPERIMENT_N]\n",
    "DAMAGE_N = [0, 0, 3][EXPERIMENT_N]  # Number of patterns to damage in a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_image(url, max_size=TARGET_SIZE):\n",
    "  r = requests.get(url)\n",
    "  img = PIL.Image.open(io.BytesIO(r.content))\n",
    "  img.thumbnail((max_size, max_size), PIL.Image.ANTIALIAS)\n",
    "  img = np.float32(img)/255.0\n",
    "  # premultiply RGB by Alpha\n",
    "  img[..., :3] *= img[..., 3:]\n",
    "  return img\n",
    "\n",
    "def load_emoji(emoji):\n",
    "  code = hex(ord(emoji))[2:].lower()\n",
    "  url = 'https://github.com/googlefonts/noto-emoji/raw/master/png/128/emoji_u%s.png'%code\n",
    "  return load_image(url)\n",
    "\n",
    "\n",
    "def to_rgba(x):\n",
    "  return x[:,:4,:,:]\n",
    "\n",
    "def to_alpha(x):\n",
    "  return torch.clamp(x[:, 3:4, :, :], min=0.0, max=1.0)\n",
    "  # return tf.clip_by_value(x[..., 3:4], 0.0, 1.0)\n",
    "\n",
    "def to_rgb(x):\n",
    "  # assume rgb premultiplied by alpha\n",
    "  rgb, a = x[:, :3, :, :], to_alpha(x)\n",
    "  return 1.0-a+rgb\n",
    "\n",
    "def get_living_mask(x):\n",
    "  alpha = x[:, 3:4, :, :]\n",
    "  # input 4d tensor, ksize (size of window for each dimension), stride for each dimension \n",
    "  # return torch.nn.functional.max_pool2d(alpha, 3, 1)\n",
    "  return torch.nn.functional.max_pool2d(input=alpha, kernel_size=3, stride=1, padding=1) > 0.1\n",
    "\n",
    "def make_seed(size, n=1):\n",
    "  x = np.zeros([n, size, size, CHANNEL_N], np.float32)\n",
    "  x[:, size//2, size//2, 3:] = 1.0\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Train Utilities (SamplePool, Damage)\n",
    "class SamplePool:\n",
    "  def __init__(self, *, _parent=None, _parent_idx=None, **slots):\n",
    "    self._parent = _parent\n",
    "    self._parent_idx = _parent_idx\n",
    "    self._slot_names = slots.keys()\n",
    "    self._size = None\n",
    "    for k, v in slots.items():\n",
    "      if self._size is None:\n",
    "        self._size = len(v)\n",
    "      assert self._size == len(v)\n",
    "      setattr(self, k, np.asarray(v))\n",
    "\n",
    "  def sample(self, n):\n",
    "    idx = np.random.choice(self._size, n, False)\n",
    "    batch = {k: getattr(self, k)[idx] for k in self._slot_names}\n",
    "    batch = SamplePool(**batch, _parent=self, _parent_idx=idx)\n",
    "    return batch\n",
    "\n",
    "  def commit(self):\n",
    "    for k in self._slot_names:\n",
    "      getattr(self._parent, k)[self._parent_idx] = getattr(self, k)\n",
    "\n",
    "# 3 72 72 \n",
    "def make_circle_masks(n, h, w):\n",
    "  x = torch.linspace(-1.0, 1.0, w)[None, None, :]\n",
    "  y = torch.linspace(-1.0, 1.0, h)[None, :, None]\n",
    "  center = torch.FloatTensor(2, n, 1, 1).uniform_(-0.5, 0.5)\n",
    "  r = torch.FloatTensor(n, 1, 1).uniform_(0.1, 0.4)\n",
    "  x, y = (x-center[0])/r, (y-center[1])/r\n",
    "  mask = (x*x+y*y < 1.0).type(torch.FloatTensor)\n",
    "  print('MASK - permute', mask)\n",
    "  return mask\n",
    "\n",
    "def generate_pool_figures(pool, step_i):\n",
    "  tiled_pool = tile2d(to_rgb(pool.x[:49]))\n",
    "  fade = np.linspace(1.0, 0.0, 72)\n",
    "  ones = np.ones(72) \n",
    "  tiled_pool[:, :72] += (-tiled_pool[:, :72] + ones[None, :, None]) * fade[None, :, None] \n",
    "  tiled_pool[:, -72:] += (-tiled_pool[:, -72:] + ones[None, :, None]) * fade[None, ::-1, None]\n",
    "  tiled_pool[:72, :] += (-tiled_pool[:72, :] + ones[:, None, None]) * fade[:, None, None]\n",
    "  tiled_pool[-72:, :] += (-tiled_pool[-72:, :] + ones[:, None, None]) * fade[::-1, None, None]\n",
    "  imwrite('train_log/%04d_pool.jpg'%step_i, tiled_pool)\n",
    "\n",
    "def visualize_batch(x0, x, step_i):\n",
    "  vis0 = np.hstack(to_rgb(x0).numpy())\n",
    "  vis1 = np.hstack(to_rgb(x).numpy())\n",
    "  vis = np.vstack([vis0, vis1])\n",
    "  imwrite('train_log/batches_%04d.jpg'%step_i, vis)\n",
    "  print('batch (before/after):')\n",
    "  imshow(vis)\n",
    "\n",
    "def plot_loss(loss_log):\n",
    "  pl.figure(figsize=(10, 4))\n",
    "  pl.title('Loss history (log10)')\n",
    "  pl.plot(np.log10(loss_log), '.', alpha=0.1)\n",
    "  pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  ...\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]]\n\n [[0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  ...\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]]\n\n [[0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  ...\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]]\n\n ...\n\n [[0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  ...\n  [0.         0.00390619 0.00390619 0.00784314]\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]]\n\n [[0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  ...\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]]\n\n [[0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  ...\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]\n  [0.         0.         0.         0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "#@title Choose Target Image { vertical-output: true}\n",
    "#url = 'https://github.com/google-research/self-organising-systems/blob/master/assets/growing_ca/planaria2_48.png?raw=true'\n",
    "#target_img = load_image(url, 48)\n",
    "\n",
    "target_img = load_emoji(TARGET_EMOJI)\n",
    "print (target_img)\n",
    "# imshow(zoom(to_rgb(target_img), 2), fmt='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Initialize Input { vertical-output: true}\n",
    "\n",
    "p = TARGET_PADDING\n",
    "target_img_tensor = torch.from_numpy(target_img)\n",
    "\n",
    "# (72,72,4)\n",
    "pad_target = torch.nn.functional.pad(target_img_tensor, pad=(0,0,p,p,p,p), mode='constant', value=0)\n",
    "h, w = pad_target.shape[:2]\n",
    "# (16, 72, 72)\n",
    "seed = np.zeros([CHANNEL_N, h, w], np.float32)\n",
    "seed[3:, h//2, w//2] = 1.0\n",
    "\n",
    "pad_target = pad_target.permute(2, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP\n",
    "class MOCKCA(nn.Module):\n",
    "    def __init__(self, channels, dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=channels*3,out_channels=dim, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=dim, out_channels=channels, kernel_size=1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ca = CellT(\n",
    "    image_size = 256,\n",
    "    patch_size = 32,\n",
    "    num_classes = 1000,\n",
    "    dim = 1024,\n",
    "    depth = 4,\n",
    "    heads = 6,\n",
    "    mlp_dim = 2048\n",
    ")\n",
    "\n",
    "origninal_ca = MOCKCA(CHANNEL_N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAModel(torch.nn.Module):\n",
    "    def __init__(self,model,channel_n=CHANNEL_N, fire_rate=CELL_FIRE_RATE):\n",
    "        super().__init__()\n",
    "        self.channel_n = channel_n\n",
    "        self.fire_rate = fire_rate\n",
    "        self.dmodel = model\n",
    "    \n",
    "    def perceive(self, x, angle=0.0):\n",
    "        identify = np.float32([0, 1, 0])\n",
    "        identify = torch.Tensor(np.outer(identify, identify))\n",
    "        sobel = np.outer([1, 2, 1], [-1, 0, 1]) / 8.0  # Sobel filter\n",
    "\n",
    "        dx = torch.Tensor(sobel)\n",
    "        dy = torch.Tensor(sobel.T)\n",
    "\n",
    "        c, s = torch.cos(torch.Tensor([angle])), torch.sin(torch.Tensor([angle]))\n",
    "        x_direction =  c*dx-s*dy\n",
    "        y_direction =  s*dx+c*dy\n",
    "\n",
    "        # TODO - Change earlier in code\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        i_kernel = identify[None, None, ...].repeat(self.channel_n, 1, 1, 1)  # TODO this will always be the same.\n",
    "        i_v = torch.nn.functional.conv2d(x, i_kernel, padding=1, groups=self.channel_n)\n",
    "\n",
    "        x_kernel = x_direction[None, None, ...].repeat(self.channel_n, 1, 1, 1)\n",
    "        x_v = torch.nn.functional.conv2d(x, x_kernel, padding=1, groups=self.channel_n)\n",
    "        y_kernel = y_direction[None, None, ...].repeat(self.channel_n, 1, 1, 1)\n",
    "        y_v = torch.nn.functional.conv2d(x, y_kernel, padding=1, groups=self.channel_n)\n",
    "\n",
    "        stacked_image = torch.cat([i_v, x_v, y_v], 1)\n",
    "        return stacked_image\n",
    "        # KERNEL SHAPE (3, 3, 16, 3)\n",
    "        # X SHAPE (1, 3, 3, 16)\n",
    "        # Y SHAPE (1, 3, 3, 48)\n",
    "        \n",
    "        # Actual Below\n",
    "        # KERNEL SHAPE (3, 3, 16, 3)\n",
    "        # X SHAPE (8, 72, 72, 16)\n",
    "        # Y SHAPE (8, 72, 72, 48)\n",
    "\n",
    "    \n",
    "    def forward(self,  x, fire_rate=None, angle=0.0, step_size=1.0):\n",
    "        pre_life_mask = get_living_mask(x)\n",
    "\n",
    "        y = self.perceive(x, angle)\n",
    "        dx = self.dmodel(y)*step_size\n",
    "        if fire_rate is None:\n",
    "            fire_rate = self.fire_rate\n",
    "        update_mask = torch.FloatTensor(*list(x[:,:1,:,:].size())).uniform_(0.0, 1.0) <= fire_rate\n",
    "        x += dx * (update_mask).type(torch.FloatTensor)\n",
    "\n",
    "        post_life_mask = get_living_mask(x)\n",
    "        life_mask = pre_life_mask & post_life_mask\n",
    "        return x * life_mask.type(torch.FloatTensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "caModel = CAModel(ca)\n",
    "origninalCAModel = CAModel(origninal_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "40949736\norginal params 8336\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "total_params = sum(reduce( lambda a, b: a*b, x.size()) for x in caModel.parameters())\n",
    "orginal_parms = sum(reduce( lambda a, b: a*b, x.size()) for x in origninalCAModel.parameters())\n",
    "print(total_params)\n",
    "print('orginal params', orginal_parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CAModel(\n  (dmodel): MOCKCA(\n    (net): Sequential(\n      (0): Conv2d(48, 128, kernel_size=(1, 1), stride=(1, 1))\n      (1): ReLU()\n      (2): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "print(origninalCAModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training\n",
    "def loss_f(x):\n",
    "    return torch.mean(torch.square_(to_rgba(x)-pad_target), [-1,-2,-3])\n",
    "\n",
    "# ca = CAModel()\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "lr = 2e-3\n",
    "# lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "#     [2000], [lr, lr*0.1])\n",
    "# trainer = tf.keras.optimizers.Adam(lr_sched)\n",
    "\n",
    "adam = torch.optim.Adam(params, lr=lr)\n",
    "optimizer = torch.optim.lr_scheduler.StepLR(adam, step_size=2000, gamma=0.1)\n",
    "\n",
    "\n",
    "# loss0 = loss_f(seed).numpy()\n",
    "# pool = SamplePool(x=np.repeat(seed[None, ...], POOL_SIZE, 0))\n",
    "\n",
    "!mkdir -p train_log && rm -f train_log/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-ddb9607b7397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mstep_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-ddb9607b7397>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0miter_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "def train_step(x):\n",
    "  iter_n = torch.FloatTensor([]).uniform_(64, 96)\n",
    "  for i in torch.range(iter_n) :\n",
    "    x = ca(x)\n",
    "  return x\n",
    "\n",
    "for i in range(8000+1):\n",
    "    x0 = np.repeat(seed[None, ...], BATCH_SIZE, 0)\n",
    "  \n",
    "    optimizer.zero_grad()\n",
    "    output = train_step(x0)\n",
    "    loss = torch.mean(loss_fn(output))\n",
    "    loss_objective = loss\n",
    "    loss_objective.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    step_i = len(loss_log)\n",
    "    loss_log.append(loss.numpy())\n",
    "    \n",
    "    if step_i%10 == 0:\n",
    "        generate_pool_figures(pool, step_i)\n",
    "    if step_i%100 == 0:\n",
    "        clear_output()\n",
    "        visualize_batch(x0, output, step_i)\n",
    "        plot_loss(loss_log)\n",
    "        # export_model(ca, 'train_log/%04d'%step_i)\n",
    "\n",
    "    print('\\r step: %d, log10(loss): %.3f'%(len(loss_log), np.log10(loss)), end='')"
   ]
  }
 ]
}